{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"nb005-pytorch-bert-for-ner.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbVABiahs17b","executionInfo":{"status":"ok","timestamp":1619571203011,"user_tz":-540,"elapsed":804,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"f2231408-594e-416f-bd05-7c5f5f737308"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Apr 28 00:53:22 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bdaoU9CrtClz","executionInfo":{"status":"ok","timestamp":1619571207952,"user_tz":-540,"elapsed":944,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"2b4eafdb-e135-4bc5-dcda-906367375e96"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94vP8PHQtQL-","executionInfo":{"status":"ok","timestamp":1619571212432,"user_tz":-540,"elapsed":2055,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"142e5241-cacf-400a-8e02-504b327427f2"},"source":["%cd /content/drive/MyDrive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/notebooks"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dHugIDq0sALu"},"source":["This notebook shows how to fine-tune a BERT model (from huggingface) for our dataset recognition task.\n","\n","Note that internet is needed during the training phase (for downloading the bert-base-cased model). Internet can be turned off during prediction."]},{"cell_type":"markdown","metadata":{"id":"kTPntd9esAL4"},"source":["## Install packages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TpzFYS6tlxC","executionInfo":{"status":"ok","timestamp":1619571226407,"user_tz":-540,"elapsed":12092,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"1421eb0e-bf00-4553-cff6-f04948be08d6"},"source":["#!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n","!pip install datasets --no-index --find-links=file:///content/drive/MyDrive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/input/coleridge-packages/packages/datasets"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Looking in links: file:///content/drive/MyDrive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/input/coleridge-packages/packages/datasets\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.7)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.7)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"jVuAv21HsAL4","executionInfo":{"status":"ok","timestamp":1619571270060,"user_tz":-540,"elapsed":41298,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"ddbb372d-72d0-42b7-9f03-1f9dcaa97b83"},"source":["!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n","!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n","!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: seqeval==1.2.2 from file:///content/drive/My%20Drive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl in /usr/local/lib/python3.7/dist-packages (1.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==1.2.2) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.1)\n","Requirement already satisfied: tokenizers==0.10.1 from file:///content/drive/My%20Drive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl in /usr/local/lib/python3.7/dist-packages (0.10.1)\n","Requirement already satisfied: transformers==4.5.0.dev0 from file:///content/drive/My%20Drive/colab_notebooks/kaggle/Kaggle-Coleridge-Initiative/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl in /usr/local/lib/python3.7/dist-packages (4.5.0.dev0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (3.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (20.9)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (0.10.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0.dev0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0.dev0) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DDBDvo4csAL5"},"source":["# Import"]},{"cell_type":"code","metadata":{"trusted":true,"id":"jfEdYkccsAL6","executionInfo":{"status":"ok","timestamp":1619571292313,"user_tz":-540,"elapsed":15849,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}}},"source":["import os\n","import re\n","import json\n","import time\n","import datetime\n","import random\n","import glob\n","import importlib\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","random.seed(123)\n","np.random.seed(456)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"9QIuiG0asAL6","executionInfo":{"status":"ok","timestamp":1619571300237,"user_tz":-540,"elapsed":6256,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}}},"source":["# copy my_seqeval.py to the working directory because the input directory is non-writable\n","#!cp /kaggle/input/coleridge-packages/my_seqeval.py ./\n","!cp ../input/coleridge-packages/my_seqeval.py ./"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cCwQ5rhuPGy","executionInfo":{"status":"ok","timestamp":1619571302229,"user_tz":-540,"elapsed":1351,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"f01374d2-642a-43f1-e4ac-30c94cd867f8"},"source":["!ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["eda-coleridge-initiative.ipynb\n","kagglenb003-annotation-data.ipynb\n","kagglenb005-pytorch-bert-for-ner.ipynb\n","localnb001-transformers-ner\n","localnb001-transformers-ner.ipynb\n","my_seqeval.py\n","nb003-annotation-data\n","nb003-annotation-data.ipynb\n","nb005-pytorch-bert-for-ner.ipynb\n","NERDA\n","pytorch-bert-for-named-entity-recognition.ipynb\n","pytorch-xla-env-setup.py\n","setup_kaggle.ipynb\n","torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n","torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n","torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y1TvCs3NsAL7"},"source":["# Hyper-parameters"]},{"cell_type":"code","metadata":{"trusted":true,"id":"RhW7ZDKRsAL7","executionInfo":{"status":"ok","timestamp":1619571306839,"user_tz":-540,"elapsed":691,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}}},"source":["MAX_LENGTH = 64 # max no. words for each sentence.\n","OVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n","\n","MAX_SAMPLE = None # set a small number for experimentation, set None for production."],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_XwNllYFsAL7"},"source":["# Load data"]},{"cell_type":"code","metadata":{"trusted":true,"id":"eY9RqsJHsAL8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619571341262,"user_tz":-540,"elapsed":31076,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"7c7cf2e3-398a-49a6-af27-fb2d0c2672f6"},"source":["train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\n","paper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\n","\n","train = pd.read_csv(train_path)\n","train = train[:MAX_SAMPLE]\n","print(f'No. raw training rows: {len(train)}')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["No. raw training rows: 19661\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LToNKh_isAL8"},"source":["Group by publication, training labels should have the same form as expected output."]},{"cell_type":"code","metadata":{"trusted":true,"id":"yzOAtA9CsAL8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619571347800,"user_tz":-540,"elapsed":1720,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"e22d4cb8-7876-4420-9e54-92fcd20b229c"},"source":["train = train.groupby('Id').agg({\n","    'pub_title': 'first',\n","    'dataset_title': '|'.join,\n","    'dataset_label': '|'.join,\n","    'cleaned_label': '|'.join\n","}).reset_index()\n","\n","print(f'No. grouped training rows: {len(train)}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["No. grouped training rows: 14316\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2RjiUj1n4FoY"},"source":["#!cp -r {paper_train_folder} /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UeYZ7gvVsAL9","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1619569619052,"user_tz":-540,"elapsed":292150,"user":{"displayName":"文系データサイエンティスト","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRDRSQ3DBbQ81iOVzkYeSWlBKjBWw5tKBmtXzVlw=s64","userId":"18359745667022839599"}},"outputId":"6cd914bf-ea5c-434b-a521-16a0e4fe7e63"},"source":["papers = {}\n","for paper_id in train['Id'].unique():\n","    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n","        paper = json.load(f)\n","        papers[paper_id] = paper"],"execution_count":15,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-e0a38eb861c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpaper_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{paper_train_folder}/{paper_id}.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpaper_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"QxEkA-UhsAL9"},"source":["# Transform data to NER format"]},{"cell_type":"code","metadata":{"trusted":true,"id":"HfqzpqX4sAL9"},"source":["def clean_training_text(txt):\n","    \"\"\"\n","    similar to the default clean_text function but without lowercasing.\n","    \"\"\"\n","    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n","\n","def shorten_sentences(sentences):\n","    short_sentences = []\n","    for sentence in sentences:\n","        words = sentence.split()\n","        if len(words) > MAX_LENGTH:\n","            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n","                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n","        else:\n","            short_sentences.append(sentence)\n","    return short_sentences\n","\n","def find_sublist(big_list, small_list):\n","    all_positions = []\n","    for i in range(len(big_list) - len(small_list) + 1):\n","        if small_list == big_list[i:i+len(small_list)]:\n","            all_positions.append(i)\n","    \n","    return all_positions\n","\n","def tag_sentence(sentence, labels): # requirement: both sentence and labels are already cleaned\n","    sentence_words = sentence.split()\n","    \n","    if labels is not None and any(re.findall(f'\\\\b{label}\\\\b', sentence)\n","                                  for label in labels): # positive sample\n","        nes = ['O'] * len(sentence_words)\n","        for label in labels:\n","            label_words = label.split()\n","\n","            all_pos = find_sublist(sentence_words, label_words)\n","            for pos in all_pos:\n","                nes[pos] = 'B'\n","                for i in range(pos+1, pos+len(label_words)):\n","                    nes[i] = 'I'\n","\n","        return True, list(zip(sentence_words, nes))\n","        \n","    else: # negative sample\n","        nes = ['O'] * len(sentence_words)\n","        return False, list(zip(sentence_words, nes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"cD7k0HejsAL-"},"source":["cnt_pos, cnt_neg = 0, 0 # number of sentences that contain/not contain labels\n","ner_data = []\n","\n","pbar = tqdm(total=len(train))\n","for i, id, dataset_label in train[['Id', 'dataset_label']].itertuples():\n","    # paper\n","    paper = papers[id]\n","    \n","    # labels\n","    labels = dataset_label.split('|')\n","    labels = [clean_training_text(label) for label in labels]\n","    \n","    # sentences\n","    sentences = set([clean_training_text(sentence) for section in paper \n","                 for sentence in section['text'].split('.') \n","                ])\n","    sentences = shorten_sentences(sentences) # make sentences short\n","    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n","    \n","    # positive sample\n","    for sentence in sentences:\n","        is_positive, tags = tag_sentence(sentence, labels)\n","        if is_positive:\n","            cnt_pos += 1\n","            ner_data.append(tags)\n","        elif any(word in sentence.lower() for word in ['data', 'study']): \n","            ner_data.append(tags)\n","            cnt_neg += 1\n","    \n","    # process bar\n","    pbar.update(1)\n","    pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n","\n","# shuffling\n","random.shuffle(ner_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k3M6GYyQsAL_"},"source":["write data to file."]},{"cell_type":"code","metadata":{"trusted":true,"id":"UQYQOhdrsAL_"},"source":["with open('train_ner.json', 'w') as f:\n","    for row in ner_data:\n","        words, nes = list(zip(*row))\n","        row_json = {'tokens' : words, 'tags' : nes}\n","        json.dump(row_json, f)\n","        f.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"an-PfAp_sAMA"},"source":["# Fine-tune a BERT model for NER"]},{"cell_type":"code","metadata":{"trusted":true,"id":"7bFPFmUZsAMA"},"source":["output_folder = \"nb005-pytorch-bert-for-ner\"\n","!mkdir {output_folder}\n","!python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n","--model_name_or_path 'bert-base-cased' \\\n","--train_file './train_ner.json' \\\n","--validation_file './train_ner.json' \\\n","--num_train_epochs 1 \\\n","--per_device_train_batch_size 8 \\\n","--per_device_eval_batch_size 8 \\\n","--save_steps 15000 \\\n","--output_dir f'./{output_folder}' \\\n","--report_to 'none' \\\n","--seed 123 \\\n","--do_train "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZGAvQsZsAMA"},"source":["After the tuning finishes, we should find our model in './output'."]},{"cell_type":"code","metadata":{"id":"7p97fXRusAMB"},"source":[""],"execution_count":null,"outputs":[]}]}