{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook simply uses matching if a dataset is in the document, it \"predicts\" the title.  It uses the 180 dataset list from the train data and adds some hand curated govt dataset titles.","metadata":{}},{"cell_type":"code","source":"# huggingface related scripts are writen between #### HF and #### HFHF\n# all other scripts by Ryosuke Horiuchi will be written between #### RIOW and #### RIOWRIOW\n\n# huggingface related scripts are copied from:\n# https://github.com/riow1983/Kaggle-Coleridge-Initiative/blob/main/notebooks/kagglenb008-pytorch-bert-for-ner-inference.ipynb\n\n\n\n#### HF\nMAX_SAMPLE = None # set a small number for experimentation, set None for production.\n\n!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:43:49.690441Z","iopub.execute_input":"2021-06-20T01:43:49.69083Z","iopub.status.idle":"2021-06-20T01:45:16.698669Z","shell.execute_reply.started":"2021-06-20T01:43:49.690753Z","shell.execute_reply":"2021-06-20T01:45:16.697815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\nimport pickle\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#### RIOW\n# import torch \n# if torch.cuda.is_available():\n#     import cupy\n#### RIOWRIOW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-20T01:45:16.702411Z","iopub.execute_input":"2021-06-20T01:45:16.702679Z","iopub.status.idle":"2021-06-20T01:45:17.516899Z","shell.execute_reply.started":"2021-06-20T01:45:16.702652Z","shell.execute_reply":"2021-06-20T01:45:17.516134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### RIOW\nrandom.seed(123)\nnp.random.seed(456)\n#### RIOWRIOW","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:45:17.518082Z","iopub.execute_input":"2021-06-20T01:45:17.518431Z","iopub.status.idle":"2021-06-20T01:45:17.525655Z","shell.execute_reply.started":"2021-06-20T01:45:17.518399Z","shell.execute_reply":"2021-06-20T01:45:17.524415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef get_count_tp_fp_fn(prediction, verbose=True):\n    preds = prediction.split(\" \")\n    if verbose:\n        print(preds)\n    tpc = 0\n    fpc = 0\n    fnc = 0\n    for pred in preds:\n        if pred == \"TP\":\n            tpc = tpc + 1\n        elif pred == \"FP\":\n            fpc = fpc + 1\n        elif pred == \"FN\":\n            fnc = fnc + 1\n    return [tpc, fpc, fnc]\n\ndef make_col_tp_fp_fn(df, col):\n    df['TP'] = df[col].apply(lambda x : x[0])\n    df['FP'] = df[col].apply(lambda x : x[1])\n    df['FN'] = df[col].apply(lambda x : x[2])\n    return df\n\ndef get_precision_recall(tp, fp, fn):\n    precision = tp / (tp+fp)\n    recall = tp / (tp + fn)\n    return precision, recall\n\ndef fbeta_score(precision, recall, beta):\n    fbeta = (1+(beta*beta))*((precision*recall)/( (beta*beta*precision) + recall))\n    return fbeta\n\ndef coleridge_initiative_jaccard(ground_truth, prediction, verbose=True):\n    gts = ground_truth.split('|')\n    pds = sorted(prediction.split('|'))\n    if verbose:\n        print(\"Ground truth : \" , gts)\n        print(\"Prediction : \", pds)\n        \n    js_scores = []\n    cf_matrix = []\n    \n    #### Counting True Positives (TP) and False Positives (FP)\n\n    for pd in pds:\n        if len(pd)>0:\n            score = -1\n            for gt in gts:\n                js = jaccard(pd, gt)\n                if js > score:\n                    score = js\n            if score >= 0.5:\n                js_scores.append(score)\n                cf_matrix.append(\"TP\")\n            else:\n                js_scores.append(score)\n                cf_matrix.append(\"FP\")\n\n    \n    #### Counting False Negatives (FN)\n    \n    for gt in gts:\n        score = -1\n        for pd in pds:\n            js = jaccard(gt, pd)\n            if js > score:\n                score = js\n        if score == 0:\n            js_scores.append(score)\n            cf_matrix.append(\"FN\")\n            \n    return js_scores, \" \".join(cf_matrix)\n    \n\ndef score_df_coleridge_initiative(output, gt_col, pred_col, beta=0.5, verbose=True):\n    \n    '''\n    This function will calculate the FBeta score for Coleridge Initiative competition \n    if given appropriate arguments\n    \n    Arguments - \n    output - Your submission dataframe that has both ground truth and prediction columns.\n    gt_col - This is the column name of ground truth column.\n    pred_col - This is the column name of predictions column.\n    beta - Beta value to calculate FBeta score.\n    \n    Returns - \n    This function will return the FBeta (beta=0.5) score.\n    \n    ## Set verbose = True to print logs    \n    '''\n    \n    ### Jaccard Similarity\n    output['evaluation'] = output.apply(lambda x: coleridge_initiative_jaccard(x[gt_col], x[pred_col], verbose=False), axis=1)\n    output['js_scores'] = output['evaluation'].apply(lambda x : x[0])\n    output['pred_type'] = output['evaluation'].apply(lambda x : x[1])\n    \n    ### TP, FP and FN \n    output['tp_fp_fn'] = output['pred_type'].apply(lambda x : get_count_tp_fp_fn(x, verbose=False))\n    output = make_col_tp_fp_fn(output, 'tp_fp_fn')\n    \n    tp = sum(output['TP'])\n    fp = sum(output['FP'])\n    fn = sum(output['FN'])\n    precision, recall = get_precision_recall(tp, fp, fn)\n    fbeta = fbeta_score(precision, recall, 0.5)\n    \n    if verbose:\n\n        print(\"TP_FP_FN : \", tp,fp,fn)\n\n    return fbeta","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:45:17.527413Z","iopub.execute_input":"2021-06-20T01:45:17.527808Z","iopub.status.idle":"2021-06-20T01:45:17.547871Z","shell.execute_reply.started":"2021-06-20T01:45:17.527769Z","shell.execute_reply":"2021-06-20T01:45:17.546977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### RIOW\nsample_sub = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\ntrain_data_path = '../input/coleridgeinitiative-show-us-the-data/train'\ntest_data_path = '../input/coleridgeinitiative-show-us-the-data/test'\ntrain_df = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/train.csv')\n#### RIOWRIOW\n\n#### HF\ntrain_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\ntrain = pd.read_csv(train_path)\ntrain = train[:MAX_SAMPLE]\n\npaper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\npapers = {}\nfor paper_id in train['Id'].unique():\n    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper\n        \n\nsample_submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\nsample_submission = pd.read_csv(sample_submission_path)\n\npaper_test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\nfor paper_id in sample_submission['Id']:\n    with open(f'{paper_test_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper\n\n\nall_labels = set()\nfor label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n    all_labels.add(str(label_1).lower())\n    all_labels.add(str(label_2).lower())\n    all_labels.add(str(label_3).lower())\n    \nprint(f'No. different labels: {len(all_labels)}')\n\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:45:17.551476Z","iopub.execute_input":"2021-06-20T01:45:17.551917Z","iopub.status.idle":"2021-06-20T01:46:14.889966Z","shell.execute_reply.started":"2021-06-20T01:45:17.55188Z","shell.execute_reply":"2021-06-20T01:46:14.888415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_json_pub(filename, train_data_path=train_data_path, output='text'):\n    json_path = os.path.join(train_data_path, (filename+'.json'))\n    headings = []\n    contents = []\n    combined = []\n    with open(json_path, 'r') as f:\n        json_decode = json.load(f)\n        for data in json_decode:\n            headings.append(data.get('section_title'))\n            contents.append(data.get('text'))\n            combined.append(data.get('section_title'))\n            combined.append(data.get('text'))\n    \n    all_headings = ' '.join(headings)\n    all_contents = ' '.join(contents)\n    all_data = '. '.join(combined)\n    \n    if output == 'text':\n        return all_contents\n    elif output == 'head':\n        return all_headings\n    else:\n        return all_data","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:14.892412Z","iopub.execute_input":"2021-06-20T01:46:14.892759Z","iopub.status.idle":"2021-06-20T01:46:14.900278Z","shell.execute_reply.started":"2021-06-20T01:46:14.892724Z","shell.execute_reply":"2021-06-20T01:46:14.899234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Converts all text to lower case, Removes special charecters, emojis and multiple spaces\n    text - Sentence that needs to be cleaned\n    '''\n    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n    text = re.sub(' +', ' ', text)\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:14.901747Z","iopub.execute_input":"2021-06-20T01:46:14.90213Z","iopub.status.idle":"2021-06-20T01:46:14.91523Z","shell.execute_reply.started":"2021-06-20T01:46:14.902094Z","shell.execute_reply":"2021-06-20T01:46:14.914395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:14.916492Z","iopub.execute_input":"2021-06-20T01:46:14.916886Z","iopub.status.idle":"2021-06-20T01:46:14.925251Z","shell.execute_reply.started":"2021-06-20T01:46:14.91685Z","shell.execute_reply":"2021-06-20T01:46:14.924644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\n# def clean_text(txt):\n#     return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:14.927821Z","iopub.execute_input":"2021-06-20T01:46:14.9281Z","iopub.status.idle":"2021-06-20T01:46:14.935189Z","shell.execute_reply.started":"2021-06-20T01:46:14.928074Z","shell.execute_reply":"2021-06-20T01:46:14.934546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\nliteral_preds = []\nfor paper_id in sample_submission['Id']:\n    paper = papers[paper_id]\n    text_1 = '. '.join(section['text'] for section in paper).lower()\n    text_2 = totally_clean_text(text_1)\n    \n    labels = set()\n    for label in all_labels:\n        if label in text_1 or label in text_2:\n            labels.add(clean_text(label))\n    \n    literal_preds.append('|'.join(labels))\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:14.936348Z","iopub.execute_input":"2021-06-20T01:46:14.936741Z","iopub.status.idle":"2021-06-20T01:46:15.042435Z","shell.execute_reply.started":"2021-06-20T01:46:14.936714Z","shell.execute_reply":"2021-06-20T01:46:15.041778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\nMAX_LENGTH = 64 # max no. words for each sentence.\nOVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\nPREDICT_BATCH = 64000 \n\n\ninputfile = \"nb005-pytorch-bert-for-ner\"\nPRETRAINED_PATH = f'../input/{inputfile}'\n\nTEST_INPUT_SAVE_PATH = './input_data'\nTEST_NER_DATA_FILE = 'test_ner_input.json'\n\nTRAIN_PATH = f'../input/{inputfile}/fold_2_train_ner.json'\nVAL_PATH = f'../input/{inputfile}/fold_2_valid_ner.json'\n\nPREDICTION_SAVE_PATH = './pred'\nPREDICTION_FILE = 'test_predictions.txt'\n\n\ntrain = train.groupby('Id').agg({\n    'pub_title': 'first',\n    'dataset_title': '|'.join,\n    'dataset_label': '|'.join,\n    'cleaned_label': '|'.join\n}).reset_index()\n\nprint(f'No. grouped training rows: {len(train)}')\n\n\n\n\n\n\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:15.044019Z","iopub.execute_input":"2021-06-20T01:46:15.044639Z","iopub.status.idle":"2021-06-20T01:46:15.397592Z","shell.execute_reply.started":"2021-06-20T01:46:15.044604Z","shell.execute_reply":"2021-06-20T01:46:15.396695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\ndef clean_training_text(txt):\n    \"\"\"\n    similar to the default clean_text function but without lowercasing.\n    \"\"\"\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n\ndef shorten_sentences(sentences):\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:15.399214Z","iopub.execute_input":"2021-06-20T01:46:15.399586Z","iopub.status.idle":"2021-06-20T01:46:15.406136Z","shell.execute_reply.started":"2021-06-20T01:46:15.399549Z","shell.execute_reply":"2021-06-20T01:46:15.405188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\ntest_rows = [] # test data in NER format\npaper_length = [] # store the number of sentences each paper has\n\nfor paper_id in sample_submission['Id']:\n    # load paper\n    paper = papers[paper_id]\n    \n    # extract sentences\n    sentences = [clean_training_text(sentence) for section in paper \n                 for sentence in section['text'].split('.')\n                ]\n    sentences = shorten_sentences(sentences) # make sentences short\n    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n    sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n        \n    # collect all sentences in json\n    for sentence in sentences:\n        sentence_words = sentence.split()\n        dummy_tags = ['O']*len(sentence_words)\n        test_rows.append({'tokens' : sentence_words, 'tags' : dummy_tags})\n    \n    # track which sentence belongs to which data point\n    paper_length.append(len(sentences))\n    \nprint(f'total number of sentences: {len(test_rows)}')\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:15.407605Z","iopub.execute_input":"2021-06-20T01:46:15.408262Z","iopub.status.idle":"2021-06-20T01:46:15.454791Z","shell.execute_reply.started":"2021-06-20T01:46:15.408222Z","shell.execute_reply":"2021-06-20T01:46:15.453982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\nos.environ[\"MODEL_PATH\"] = f\"{PRETRAINED_PATH}\"\nos.environ[\"TRAIN_FILE\"] = f\"{TRAIN_PATH}\"\nos.environ[\"VALIDATION_FILE\"] = f\"{VAL_PATH}\"\nos.environ[\"TEST_FILE\"] = f\"{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}\"\nos.environ[\"OUTPUT_DIR\"] = f\"{PREDICTION_SAVE_PATH}\"\n\n\n\n# copy my_seqeval.py to the working directory because the input directory is non-writable\n!cp /kaggle/input/coleridge-packages/my_seqeval.py ./\n\n# make necessart directories and files\nos.makedirs(TEST_INPUT_SAVE_PATH, exist_ok=True)\n\n\ndef bert_predict():\n    !python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n    --model_name_or_path $MODEL_PATH \\\n    --train_file $TRAIN_FILE \\\n    --validation_file $VALIDATION_FILE \\\n    --test_file $TEST_FILE \\\n    --output_dir $OUTPUT_DIR \\\n    --report_to 'none' \\\n    --seed 123 \\\n    --do_predict\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:15.456338Z","iopub.execute_input":"2021-06-20T01:46:15.456673Z","iopub.status.idle":"2021-06-20T01:46:16.114102Z","shell.execute_reply.started":"2021-06-20T01:46:15.456639Z","shell.execute_reply":"2021-06-20T01:46:16.112954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\nbert_outputs = []\nfor batch_begin in range(0, len(test_rows), PREDICT_BATCH):\n    # write data rows to input file\n    with open(f'{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}', 'w') as f:\n        for row in test_rows[batch_begin:batch_begin+PREDICT_BATCH]:\n            json.dump(row, f)\n            f.write('\\n')\n    \n    # remove output dir\n    !rm -r $OUTPUT_DIR\n    \n    # do predict\n    bert_predict()\n    \n    # read predictions\n    with open(f'{PREDICTION_SAVE_PATH}/{PREDICTION_FILE}') as f:\n        this_preds = f.read().split('\\n')[:-1]\n        bert_outputs += [pred.split() for pred in this_preds]\n\n\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:46:16.117582Z","iopub.execute_input":"2021-06-20T01:46:16.117875Z","iopub.status.idle":"2021-06-20T01:47:23.996093Z","shell.execute_reply.started":"2021-06-20T01:46:16.117841Z","shell.execute_reply":"2021-06-20T01:47:23.991166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### HF\n# get test sentences\ntest_sentences = [row['tokens'] for row in test_rows]\ndel test_rows\n\n\n\nbert_dataset_labels = [] # store all dataset labels for each publication\nfor length in paper_length:\n    labels = set()\n    for sentence, pred in zip(test_sentences[:length], bert_outputs[:length]):\n        curr_phrase = ''\n        for word, tag in zip(sentence, pred):\n            if tag == 'B': # start a new phrase\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n                curr_phrase = word\n            elif tag == 'I' and curr_phrase: # continue the phrase\n                curr_phrase += ' ' + word\n            else: # end last phrase (if any)\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n        # check if the label is the suffix of the sentence\n        if curr_phrase:\n            labels.add(curr_phrase)\n            curr_phrase = ''\n    \n    # record dataset labels for this publication\n    bert_dataset_labels.append(labels)\n    \n    del test_sentences[:length], bert_outputs[:length]\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:24.00133Z","iopub.execute_input":"2021-06-20T01:47:24.001977Z","iopub.status.idle":"2021-06-20T01:47:24.024487Z","shell.execute_reply.started":"2021-06-20T01:47:24.001899Z","shell.execute_reply":"2021-06-20T01:47:24.023434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv('../input/bigger-govt-dataset-list/data_set_800.csv')\n#df2=pd.read_csv(\"../input/coleridge-additional-gov-datasets-22000popular/additional_gov_datasets_22000popular.csv\")\n#df2=pd.read_csv(\"../input/add-dataset-coloridge/data_set_800_with2000popular.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:24.027612Z","iopub.execute_input":"2021-06-20T01:47:24.028146Z","iopub.status.idle":"2021-06-20T01:47:24.060777Z","shell.execute_reply.started":"2021-06-20T01:47:24.028108Z","shell.execute_reply":"2021-06-20T01:47:24.059901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n\n#### remove >.5 jaccard matches from predicitons\ndef jaccard_similarity(s1, s2):\n    l1 = s1.split(\" \")\n    l2 = s2.split(\" \")    \n    intersection = len(list(set(l1).intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) / union\n\n\n#### HF\n# def jaccard_similarity(s1, s2):\n#     l1 = s1.split(\" \")\n#     l2 = s2.split(\" \")    \n#     intersection = len(list(set(l1).intersection(l2)))\n#     union = (len(l1) + len(l2)) - intersection\n#     return float(intersection) / union\n#### HFHF\n\n#############################\n#path=train_data_path\npath=test_data_path\n\n#for training use train_sample\n\n#for submission use sample_sub\n\n#############\n\ncolumn_names = [\"Id\", \"PredictionString\"]\n\nsubmission = pd.DataFrame(columns = column_names)\nfn_list=[]\nfn_text=[]\nall_list=[]\nall_text=[]\nto_append=[]\nfor index, row in sample_sub.iterrows():\n#for index, row in tqdm(train_df.iterrows()):\n    to_append=[row['Id'],'']\n    large_string = str(read_json_pub(row['Id'],path))\n    clean_string=text_cleaning(large_string)\n    for index, row2 in df2.iterrows():\n        query_string = str(row2['title'])\n        if query_string in clean_string:\n            if to_append[1]!='' and clean_text(query_string) not in to_append[1]:\n                to_append[1]=to_append[1]+'|'+clean_text(query_string)\n            if to_append[1]=='':\n                to_append[1]=clean_text(query_string)\n\n                \n    if to_append[1]=='':\n        fn_list+=[row['Id']]\n        fn_text+=[large_string]\n    all_list+=[row['Id']]\n    all_text+=[large_string]\n\n\n    df_length = len(submission)\n    submission.loc[df_length] = to_append\nsubmission.to_csv('submission.csv', index = False)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nsubmission\n","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:24.06515Z","iopub.execute_input":"2021-06-20T01:47:24.065505Z","iopub.status.idle":"2021-06-20T01:47:25.414939Z","shell.execute_reply.started":"2021-06-20T01:47:24.065471Z","shell.execute_reply":"2021-06-20T01:47:25.414237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#%%time\n#!pip uninstall fastai en-core-web-sm en-core-web-lg spacy -y -q\n#!pip install ../input/spacy3/catalogue-2.0.3-py3-none-any.whl ../input/spacy3/typer-0.3.2-py3-none-any.whl ../input/spacy3/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl ../input/spacy3/pathy-0.5.2-py3-none-any.whl ../input/spacy3/smart_open-3.0.0-py3-none-any.whl ../input/spacy3/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl ../input/spacy3/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl ../input/spacy3/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl ../input/spacy3/spacy_legacy-3.0.5-py2.py3-none-any.whl -q\n#!pip install ../input/spacy3/en_core_web_lg-3.0.0-py3-none-any.whl ../input/spacy3/en_core_web_md-3.0.0-py3-none-any.whl ../input/spacy3/en_core_web_sm-3.0.0-py3-none-any.whl -q\n#!pip install ../input/spacy3/spacy_alignments-0.8.3-cp37-cp37m-manylinux2014_x86_64.whl ../input/spacy3/spacy_transformers-1.0.2-py2.py3-none-any.whl ../input/spacy3/en_core_web_trf-3.0.0-py3-none-any.whl -q\n#import spacy\n#assert spacy.__version__ == '3.0.6'\n#import en_core_web_trf\n#import torch \n#if torch.cuda.is_available():\n#    spacy.prefer_gpu()\n#nlp = spacy.load(\"../input/spacy-cv-4-model/output/model-best\") #load the best model\n#nlp2 = spacy.load(\"../input/spacy-train-set/cv0-model-best\") #load the best model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.416221Z","iopub.execute_input":"2021-06-20T01:47:25.416597Z","iopub.status.idle":"2021-06-20T01:47:25.421992Z","shell.execute_reply.started":"2021-06-20T01:47:25.41656Z","shell.execute_reply":"2021-06-20T01:47:25.421065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n%%time\n\n\nexisting_labels = set(df2[\"title\"])\ndef nlp_label_cv(Id,text,existing_labels,nlp_list):\n    c_label=[]\n    for nlp_er0 in nlp_list:\n        doc = nlp_er0(text)\n        ent_d=set([doc.ents[i].text  for i in range(len(doc.ents)) if (doc.ents[i].label_ == 'DB_label') & (clean_text(doc.ents[i].text) != \"\")] )\n       \n\n        for ent in ent_d:\n            j_val=[jaccard(clean_text(ent.lower()), clean_text(list(existing_labels)[i]))>0.7  for i in range(len(existing_labels)) ]\n            #c_label+=set(pd.Series(list(existing_labels))[j_val] )\n            #j_val=[jaccard(clean_text(ent.lower()), clean_text(list(existing_labels)[i]))  for i in range(len(existing_labels)) ]\n            #if np.max(j_val) > 0.7:\n            #    c_label+=set(pd.Series(list(existing_labels)).iloc[np.argmax(j_val)] )\n            if sum(j_val)==0:\n                c_label+=[clean_text(str(ent).lower())]\n                #if nlp_qa0(question=\"dataset?\", context=str(ent))[\"score\"] > 0.7:\n                #    c_label+=[clean_text(nlp_qa0(question=\"dataset?\", context=str(ent))['answer'].lower())  ]\n\n\n\n        del nlp_er0\n    #del nlp_qa0\n\n    \n    return [\"|\".join(list(set(c_label)))]\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.423283Z","iopub.execute_input":"2021-06-20T01:47:25.423674Z","iopub.status.idle":"2021-06-20T01:47:25.436887Z","shell.execute_reply.started":"2021-06-20T01:47:25.423648Z","shell.execute_reply":"2021-06-20T01:47:25.436227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################################################################################\n#############   NER推論部分_pred_nerがサブミッションファイルと同じ形式になる   ##############\n######################################################################################\n\n\"\"\"\npred_ner=pd.DataFrame(columns=[\"Id\",'PredictionString'])#\ntex_df=pd.DataFrame({\"Id\":fn_list,\"raw_text\":fn_text}).drop_duplicates()#train\n#tex_df=sample_submission_df[[\"Id\",\"raw_text\"]].drop_duplicates()#test\nId_list=[]\npred_list=[]\nfor Id in tqdm(fn_list):\n    if torch.cuda.is_available():\n        spacy.prefer_gpu()\n        torch.cuda.empty_cache()\n        cupy.get_default_memory_pool().free_all_blocks()\n    nlp_er = nlp\n    nlp_er2 = nlp2\n    #nlp_qa0=nlp_qa\n    #nlp_er.get_pipe(\"transformer\").model.attrs[\"flush_cache_chance\"] = 1\n    text = tex_df.set_index(\"Id\").loc[Id,\"raw_text\"]\n    if len(text) > 200_000:\n        text=text[0:200_000]\n    Id_list+=[Id]\n    #pred_list+=[\"|\".join(set([clean_text(doc.ents[i].text)  for i in range(len(doc.ents)) if doc.ents[i].label_ == 'DB_label' ] ))]\n    #pred_ner=pd.concat([pred_ner,nlp_lable(Id,text,existing_labels,nlp_er)],axis=0)\n    pred_list+=nlp_label_cv(Id,text,existing_labels,[nlp_er,nlp_er2])\n\n\npred_ner=pd.DataFrame({\"Id\":Id_list,'PredictionString':pred_list})   \nsum(pred_ner[\"PredictionString\"]==\"\")\n\"\"\"\n\n\n#### HF\n    \n# def jaccard_similarity(s1, s2):\n#     l1 = s1.split(\" \")\n#     l2 = s2.split(\" \")    \n#     intersection = len(list(set(l1).intersection(l2)))\n#     union = (len(l1) + len(l2)) - intersection\n#     return float(intersection) / union\n\nfiltered_bert_labels = []\nfor labels in bert_dataset_labels:\n    filtered = []\n    \n    for label in sorted(labels, key=len):\n        label = clean_text(label)\n        if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered):\n            filtered.append(label)\n    \n    filtered_bert_labels.append('|'.join(filtered))\n    \n\n#### RIOW\nfinal_predictions = []\n# for literal_match, bert_pred in zip(literal_preds, filtered_bert_labels):\n#     if literal_match:\n#         final_predictions.append(literal_match)\n#     else:\n#         final_predictions.append(bert_pred)\nfor bert_pred in filtered_bert_labels:\n    final_predictions.append(bert_pred)\n#### RIOWRIOW\n        \nsample_submission['PredictionString'] = final_predictions\n#### RIOW\npred_ner = sample_submission.copy()\n#### RIOWRIOW\n#### HFHF","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.438392Z","iopub.execute_input":"2021-06-20T01:47:25.439027Z","iopub.status.idle":"2021-06-20T01:47:25.448745Z","shell.execute_reply.started":"2021-06-20T01:47:25.438989Z","shell.execute_reply":"2021-06-20T01:47:25.448093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name=pd.Series(pred_ner[\"PredictionString\"].str.split(\"|\").sum()).value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.449872Z","iopub.execute_input":"2021-06-20T01:47:25.450327Z","iopub.status.idle":"2021-06-20T01:47:25.463313Z","shell.execute_reply.started":"2021-06-20T01:47:25.450275Z","shell.execute_reply":"2021-06-20T01:47:25.462441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tex_df=pd.DataFrame({\"Id\":all_list,\"raw_text\":all_text}).drop_duplicates()\nuse_name=name[name>100].index\ncolumn_names = [\"Id\", \"PredictionString\"]\npred_match = pd.DataFrame(columns = column_names)\nto_append=[]\nfor Id in tqdm(all_list):\n#for index, row in tqdm(train_df.iterrows()):\n    to_append=[Id,'']\n    large_string = str(tex_df.set_index(\"Id\").loc[Id,\"raw_text\"])\n    clean_string=text_cleaning(large_string)\n    for row2 in use_name:\n        query_string = str(row2)\n        if query_string in clean_string:\n            if to_append[1]!='' and clean_text(query_string) not in to_append[1]:\n                to_append[1]=to_append[1]+'|'+clean_text(query_string)\n            if to_append[1]=='':\n                to_append[1]=clean_text(query_string)\n    #pred_match+=to_append\n    df_length = len(pred_match)\n    pred_match.loc[df_length] = to_append","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.465124Z","iopub.execute_input":"2021-06-20T01:47:25.465797Z","iopub.status.idle":"2021-06-20T01:47:25.574587Z","shell.execute_reply.started":"2021-06-20T01:47:25.46576Z","shell.execute_reply":"2021-06-20T01:47:25.573707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=pd.concat([submission,pred_match])\nsub[\"PredictionString\"]=sub[\"PredictionString\"].str.split(\"|\")\nsub=sub.groupby(\"Id\").sum()\n#### RIOW\n#sub[\"PredictionString\"]=[\"|\".join(list(set(sub[\"PredictionString\"][i]))) for i in range(sub.shape[0]) ]\nsub[\"PredictionString\"] = sub[\"PredictionString\"].apply(lambda x: \"|\".join(list(set(x))).strip(\"|\"))\n#### RIOWRIOW\nsub=sub.reset_index()\nsub","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:47:25.57595Z","iopub.execute_input":"2021-06-20T01:47:25.576265Z","iopub.status.idle":"2021-06-20T01:47:25.588186Z","shell.execute_reply.started":"2021-06-20T01:47:25.576229Z","shell.execute_reply":"2021-06-20T01:47:25.587246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### RIOW\n# for i in range(4):\n#     print(sub.loc[i, \"PredictionString\"])\n#     print()\n#### RIOWRIOW","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:49:18.978448Z","iopub.execute_input":"2021-06-20T01:49:18.978788Z","iopub.status.idle":"2021-06-20T01:49:18.987463Z","shell.execute_reply.started":"2021-06-20T01:49:18.978756Z","shell.execute_reply":"2021-06-20T01:49:18.986355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:49:34.211023Z","iopub.execute_input":"2021-06-20T01:49:34.211383Z","iopub.status.idle":"2021-06-20T01:49:34.216927Z","shell.execute_reply.started":"2021-06-20T01:49:34.21135Z","shell.execute_reply":"2021-06-20T01:49:34.215854Z"},"trusted":true},"execution_count":null,"outputs":[]}]}