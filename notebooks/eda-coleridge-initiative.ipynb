{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"eda-coleridge-initiative.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"c4e7-1_Vfdzs"},"source":["Reference: https://www.kaggle.com/prashansdixit/coleridge-initiative-eda-baseline-model"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"xUYb_tpnfdz1"},"source":["import warnings\n","warnings.filterwarnings('ignore', category=DeprecationWarning)\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","import os\n","import re\n","import json\n","import glob\n","from collections import defaultdict\n","from textblob import TextBlob\n","from functools import partial\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","\n","import nltk\n","import spacy\n","nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n","nlp.max_length = 4000000\n","from nltk.probability import FreqDist\n","from wordcloud import WordCloud, STOPWORDS\n","\n","from tqdm.autonotebook import tqdm\n","import string\n","\n","%matplotlib inline\n","\n","os.listdir('/kaggle/input/coleridgeinitiative-show-us-the-data/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"q7rzAdQKfdz4"},"source":["# reading csv files and train & test file paths\n","train_df = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/train.csv')\n","sample_sub = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n","train_files_path = '../input/coleridgeinitiative-show-us-the-data/train'\n","test_files_path = '../input/coleridgeinitiative-show-us-the-data/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"vfJTIEtjfdz4"},"source":["kaggle_env = False\n","if kaggle_env:\n","    dirname = \"/kaggle/input/coleridgeinitiative-show-us-the-data\"\n","else:\n","    dirname = \"\"\n","#df = pd.read_csv(os.path.join(dirname, \"train.csv\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"EKoRHjMWfdz5"},"source":["train_df[\"cleaned_label\"].value_counts(dropna=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNFEcPMnfdz5"},"source":["> There are only 130 'cleaned_label's / only 45 unique 'dataset_title's for the 14,316 training data files.\n","https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/228322"]},{"cell_type":"code","metadata":{"trusted":true,"id":"-JyX7HHhfdz5"},"source":["train_df[\"cleaned_label\"].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"n3EIvqTjfdz6"},"source":["train_df[\"dataset_title\"].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"-PdEEd17fdz6"},"source":["i = 0\n","display(train_df.iloc[i, :])\n","display(pd.read_json(os.path.join(dirname, \"train\", train_df[\"Id\"][i]+\".json\")))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"5orq3B7-fdz6"},"source":["i = 1\n","display(train_df.iloc[i, :])\n","display(pd.read_json(os.path.join(dirname, \"train\", train_df[\"Id\"][i]+\".json\")))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"DzLMC-_mfdz7"},"source":["i = 3\n","display(train_df.iloc[i, :])\n","display(pd.read_json(os.path.join(dirname, \"train\", train_df[\"Id\"][i]+\".json\")))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wd4IZUG3fdz7"},"source":["def read_append_return(filename, train_files_path=train_files_path, output='text'):\n","    \"\"\"\n","    Function to read json file and then return the text data from them and append to the dataframe\n","    \"\"\"\n","    json_path = os.path.join(train_files_path, (filename+'.json'))\n","    headings = []\n","    contents = []\n","    combined = []\n","    with open(json_path, 'r') as f:\n","        json_decode = json.load(f)\n","        for data in json_decode:\n","            headings.append(data.get('section_title'))\n","            contents.append(data.get('text'))\n","            combined.append(data.get('section_title'))\n","            combined.append(data.get('text'))\n","    \n","    all_headings = ' '.join(headings)\n","    all_contents = ' '.join(contents)\n","    all_data = '. '.join(combined)\n","    \n","    if output == 'text':\n","        return all_contents\n","    elif output == 'head':\n","        return all_headings\n","    else:\n","        return all_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WSEoqbw2fdz8"},"source":["%%time\n","tqdm.pandas()   #tqdm is used to show any code running with a progress bar. \n","train_df['text'] = train_df['Id'].progress_apply(read_append_return)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"zXeL8iNqfdz8"},"source":["train_df.sample(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"5d8DWNLyfdz8"},"source":["train_df[\"text\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"G9Ic7MQ_fdz9"},"source":["%%time\n","tqdm.pandas()\n","sample_sub['text'] = sample_sub['Id'].progress_apply(partial(read_append_return, train_files_path=test_files_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"2f2HG7VHfdz9"},"source":["sample_sub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"d1uKtg0_fdz9"},"source":["sample_sub[\"text\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"7XZIaLuffdz9"},"source":["sample_sub[\"text\"][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ml6nCU0ifdz-"},"source":["sample_sub[\"text\"][2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QQeBjOQjfdz-"},"source":["sample_sub[\"text\"][3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"i_v7w-4Yfdz-"},"source":["def text_cleaning(text):\n","    '''\n","    Converts all text to lower case, Removes special charecters, emojis and multiple spaces\n","    text - Sentence that needs to be cleaned\n","    '''\n","    text = ''.join([k for k in text if k not in string.punctuation])\n","    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n","    text = re.sub(' +', ' ', text)\n","    emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               \"]+\", flags=re.UNICODE)\n","    text = emoji_pattern.sub(r'', text)\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"VFB8LVVqfdz_"},"source":["%%time\n","tqdm.pandas()\n","train_df['text'] = train_df['text'].progress_apply(text_cleaning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ZcZOFDDkfdz_"},"source":["%%time \n","tqdm.pandas()\n","sample_sub['text'] = sample_sub['text'].progress_apply(text_cleaning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"efITi8kIfdz_"},"source":["def prepare_text(text, nlp=nlp):\n","    '''\n","    Returns the text after stop-word removal and lemmatization.\n","    text - Sentence to be processed\n","    nlp - Spacy NLP model\n","    '''\n","    doc = nlp(text)\n","    lemma_list = [token.lemma_ for token in doc if not token.is_stop]\n","    lemmatized_sentence = ' '.join(lemma_list)\n","    \n","    return lemmatized_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"gk7H-TcAfd0A"},"source":["def clean_text(txt):\n","    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"nRxPx8fLfd0A"},"source":["# %%time\n","# tqdm.pandas()\n","# train_df['text'] = train_df['text'].progress_apply(prepare_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"H6jroI7cfd0A"},"source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from transformers import pipeline\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n","model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n","nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"_7UQlgmkfd0A"},"source":["i = 2\n","example = train_df[\"text\"][i][:100]\n","ner_results = nlp(example)\n","print(ner_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"EZT6sbP_fd0B"},"source":["train_df[\"ner_result\"] = train_df[\"text\"].apply(lambda x: nlp(x[:100]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UgR79Vd3fd0B"},"source":["#example = \"My name is Wolfgang and I live in Berlin\"\n","#ner_results = nlp(example)\n","#print(ner_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"B5ExOlhIfd0B"},"source":["train_df[\"ner_result\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UjZopYSvfd0B"},"source":["train_df_ = train_df[train_df[\"ner_result\"].apply(lambda x: len(x)) > 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Uk6OXMbcfd0C"},"source":["train_df_[\"ner_result\"][85]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rddF3vGufd0C"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UCEequcRfd0C"},"source":["temp_1 = [x.lower() for x in train_df['dataset_label'].unique()]\n","temp_2 = [x.lower() for x in train_df['dataset_title'].unique()]\n","temp_3 = [x.lower() for x in train_df['cleaned_label'].unique()]\n","\n","existing_labels = set(temp_1 + temp_2 + temp_3)\n","id_list = []\n","lables_list = []\n","for index, row in tqdm(sample_sub.iterrows()):\n","    sample_text = row['text']\n","    row_id = row['Id']\n","    temp_df = train_df[train_df['text'] == text_cleaning(sample_text)]\n","    cleaned_labels = temp_df['cleaned_label'].to_list()\n","    for known_label in existing_labels:\n","        if known_label in sample_text.lower():\n","            cleaned_labels.append(clean_text(known_label))\n","    cleaned_labels = [clean_text(x) for x in cleaned_labels]\n","    cleaned_labels = set(cleaned_labels)\n","    lables_list.append('|'.join(cleaned_labels))\n","    id_list.append(row_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"GUoJaDe3fd0C"},"source":["submission = pd.DataFrame()\n","submission['Id'] = id_list\n","submission['PredictionString'] = lables_list\n","display(submission)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"__3aWm9afd0D"},"source":["submission[\"PredictionString\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"KuAY1WbQfd0D"},"source":["submission[\"PredictionString\"][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"vhDHGgXlfd0D"},"source":["submission[\"PredictionString\"][2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"4MuQ-xDGfd0D"},"source":["submission[\"PredictionString\"][3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"7JQjjqv1fd0E"},"source":["submission.to_csv('submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"D6ZAEpZ2fd0E"},"source":[""],"execution_count":null,"outputs":[]}]}